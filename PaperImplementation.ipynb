{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selmakurtovic4/Generating-Music-Using-Deep-Learning/blob/main/PaperImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if len(device_name) > 0:\n",
        "    print(\"Found GPU at: {}\".format(device_name))\n",
        "else:\n",
        "    device_name = \"/device:CPU:0\"\n",
        "    print(\"No GPU, using {}.\".format(device_name))"
      ],
      "metadata": {
        "id": "C5_hSnZnudd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b19ecea-c6e9-4af8-dd07-3827f909bb6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rqF6VYkZcHO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!git clone https://github.com/selmakurtovic4/ZavrsniRad.git\n",
        "os.chdir('/content/ZavrsniRad')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import music21\n",
        "from keras.utils import to_categorical\n",
        "from glob import glob\n",
        "import IPython\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import os\n",
        "from music21 import converter, instrument, note, chord, stream,duration\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten, concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import*\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image\n",
        "from tensorflow.keras.layers import Input, LSTM, Dropout, Flatten, Dense, Activation, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "bFFPfAvrZfoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs = glob('./Datasets/TheBeatles/*.mid')"
      ],
      "metadata": {
        "id": "4V7TCh3KZqaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes(songs):\n",
        "    notes = []\n",
        "    for file in songs:\n",
        "        try:\n",
        "            midi = converter.parse(file)\n",
        "            notes_to_parse = []\n",
        "            try:\n",
        "                Score = instrument.partitionByInstrument(midi)\n",
        "            except:\n",
        "                pass\n",
        "            if Score and len(Score)>1: # if parts have instrument parts and if it has more than one instrument\n",
        "                notes_to_parse = Score.parts[1].recurse()\n",
        "            else:\n",
        "                notes_to_parse = midi.flat.notes\n",
        "\n",
        "            for element in notes_to_parse:\n",
        "                if isinstance(element, note.Note):\n",
        "                    element={\"pitch\": str(element.pitch), \"duration\": str(element.duration.quarterLength), \"played\":1 }\n",
        "                    notes.append(element)\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    normalOrderChord='.'.join(str(n) for n in element.normalOrder)\n",
        "                    element={\"pitch\":  normalOrderChord, \"duration\": str(element.duration.quarterLength), \"played\":1 }\n",
        "                    notes.append(element)\n",
        "                elif isinstance(element, note.Rest):\n",
        "                    element={\"pitch\": \"r\", \"duration\": str(element.duration.quarterLength), \"played\":1 }\n",
        "                    notes.append(element)\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing MIDI file {file}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Save the notes to a file\n",
        "    with open('Data/notes.json', 'w') as filepath:\n",
        "        json.dump(notes, filepath)\n",
        "\n",
        "    return notes"
      ],
      "metadata": {
        "id": "onGDRTbi-KY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_duration_dictionary(notes):\n",
        "     durations = [element[\"duration\"] for element in notes]\n",
        "     duration_names = sorted(set(item for item in durations))\n",
        "     unique_duration_num=len(duration_names)\n",
        "     duration_to_int = {note: value for value, note in enumerate(duration_names, start=0)}\n",
        "\n",
        "     return  unique_duration_num,duration_to_int\n"
      ],
      "metadata": {
        "id": "GC4O4yNPSBjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_pitch_dictionary(notes):\n",
        "     pitches = [element[\"pitch\"] for element in notes]\n",
        "     pitch_names = sorted(set(item for item in pitches))\n",
        "     unique_count=len(pitch_names)\n",
        "     pitch_to_int = dict((note, number) for number, note in enumerate(pitch_names))\n",
        "\n",
        "     return unique_count,pitch_to_int"
      ],
      "metadata": {
        "id": "1r9xPS3jG8zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data(data):\n",
        "  scaler = MinMaxScaler()\n",
        "  normalized_data = scaler.fit_transform(data)\n",
        "  return normalized_data"
      ],
      "metadata": {
        "id": "80-FmYD_ZgS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_duration_value(duration):\n",
        "   num=1\n",
        "   base_value= 1/16\n",
        "   middle=1/32\n",
        "   decimalValue=1.0\n",
        "   while(duration > base_value):\n",
        "    duration=duration-base_value\n",
        "    num=num+1\n",
        "    decimalValue=duration\n",
        "   if(decimalValue<middle):\n",
        "    num=num-1\n",
        "   duration=num/16\n",
        "   return duration"
      ],
      "metadata": {
        "id": "V1i_PVhK3kTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_duration_array(notes):\n",
        "  durations = [element[\"duration\"] for element in notes]\n",
        "  #transform to real numbers\n",
        "  for note in notes:\n",
        "    note[\"duration\"]=round(eval(note[\"duration\"]),2)\n",
        "  #transform to 1/16 based values\n",
        "  base_value= 1/16\n",
        "  comparing_value=0.001\n",
        "  for index, note in enumerate(notes):\n",
        "    duration=note[\"duration\"]\n",
        "    if(duration<1):\n",
        "      new_value=transform_duration_value(duration)\n",
        "      note[\"duration\"] = new_value\n",
        "    else:\n",
        "      #create new notes, min 2\n",
        "      is_it_float=0\n",
        "      additional_value=duration-int(duration)\n",
        "      if(additional_value>0):\n",
        "         is_it_float=1\n",
        "         #additional_value=round(additional_value,2)\n",
        "      numberOfNotes=int(duration)+ is_it_float\n",
        "      numberOfInsertedNotes=numberOfNotes-1\n",
        "      note[\"duration\"]=1\n",
        "      for i in range(0,numberOfInsertedNotes-1):\n",
        "        element={\"pitch\": note[\"pitch\"], \"duration\": 1, \"played\":0 }\n",
        "        notes.insert(index+1,element)\n",
        "      if(is_it_float):\n",
        "        new_duration=transform_duration_value(additional_value)\n",
        "        element={\"pitch\": note[\"pitch\"], \"duration\": new_duration, \"played\":0 }\n",
        "        notes.insert(index+numberOfInsertedNotes,element)\n"
      ],
      "metadata": {
        "id": "XuxEVBFcKM35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes):\n",
        "    sequence_length = 50\n",
        "    prepare_duration_array(notes)\n",
        "    unique_pitch_num, pitch_dictionary = prepare_pitch_dictionary(notes)\n",
        "    unique_duration_num, duration_dictionary = prepare_duration_dictionary(notes)\n",
        "\n",
        "    print(pitch_dictionary)\n",
        "    network_input = []\n",
        "    network_out=[]\n",
        "    network_output_played=[]\n",
        "    network_output_pitch=[]\n",
        "    network_output_duration=[]\n",
        "    pitch_network_input=[]\n",
        "    duration_network_input=[]\n",
        "    played_network_input=[]\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        output_element=[]\n",
        "        notes_sequence = notes[i: i + sequence_length]\n",
        "        sequence_in = []\n",
        "        pitch_sequence_in = []\n",
        "        duration_sequence_in = []\n",
        "        played_sequence_in=[]\n",
        "        for note in notes_sequence:\n",
        "            pitch_sequence_in.append(pitch_dictionary[note[\"pitch\"]])\n",
        "            duration_sequence_in.append(duration_dictionary[note[\"duration\"] ])\n",
        "            played_sequence_in.append(note[\"played\"])\n",
        "        pitch_network_input.append(pitch_sequence_in)\n",
        "        duration_network_input.append(duration_sequence_in)\n",
        "        played_network_input.append(played_sequence_in)\n",
        "\n",
        "        output_pitch=pitch_dictionary[notes[i + sequence_length][\"pitch\"]]\n",
        "        output_duration=duration_dictionary[notes[i + sequence_length][\"duration\"]]\n",
        "        #one element of pl\n",
        "        output_played=notes[i + sequence_length][\"played\"]\n",
        "        #encode\n",
        "        length=unique_duration_num+unique_pitch_num+1\n",
        "\n",
        "        output_pitch= to_categorical(output_pitch, num_classes=unique_pitch_num)\n",
        "        output_duration=to_categorical(output_duration, num_classes=unique_duration_num)\n",
        "        output_played=to_categorical(output_played, num_classes=2)\n",
        "\n",
        "        #output arrays\n",
        "\n",
        "        network_output_pitch.append(output_pitch)\n",
        "        network_output_duration.append(output_duration)\n",
        "        network_output_played.append(output_played)\n",
        "\n",
        "    network_input.append(pitch_network_input)\n",
        "    network_input.append(duration_network_input)\n",
        "    network_input.append(played_network_input)\n",
        "\n",
        "    network_output_pitch=np.array(network_output_pitch)\n",
        "    network_output_duration=np.array(network_output_duration)\n",
        "    network_output_played=np.array(network_output_played)\n",
        "\n",
        "    print(network_input[0][0])\n",
        "    print(network_input[1][0])\n",
        "    print(network_input[2][0])\n",
        "\n",
        "    return (network_input, network_output_pitch, network_output_duration,network_output_played)"
      ],
      "metadata": {
        "id": "gkdCBnblZ7j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(unique_pitch_num, unique_duration_num, num_of_sequences):\n",
        "    pitchInput = Input(shape=(50, 1))\n",
        "    durationInput = Input(shape=(50, 1))\n",
        "    playedInput = Input(shape=(50, 1))\n",
        "\n",
        "    x = LSTM(128, return_sequences=True)(pitchInput)\n",
        "    y = LSTM(64, return_sequences=True)(durationInput)\n",
        "    z = LSTM(64, return_sequences=True)(playedInput)\n",
        "\n",
        "    combined = concatenate([x, y, z])\n",
        "    w = LSTM(128, return_sequences=True, recurrent_dropout=0, activation=\"tanh\", recurrent_activation=\"sigmoid\")(combined)\n",
        "    w = Dropout(0.2)(w)\n",
        "    w = LSTM(128, return_sequences=True, recurrent_dropout=0, activation=\"tanh\", recurrent_activation=\"sigmoid\")(w)\n",
        "    w = Flatten()(w)\n",
        "    w = Dense(256, activation='relu')(w)\n",
        "    w = Dropout(0.3)(w)\n",
        "\n",
        "    pitch_output = Dense(unique_pitch_num, activation='softmax')(w)\n",
        "    duration_output = Dense(unique_duration_num, activation='softmax')(w)\n",
        "    played_output = Dense(2, activation='softmax')(w)\n",
        "\n",
        "    model = Model(inputs=[pitchInput, durationInput, playedInput],\n",
        "                  outputs=[pitch_output, duration_output, played_output])\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=['categorical_crossentropy', 'categorical_crossentropy', 'binary_crossentropy'],\n",
        "                  metrics=[Accuracy()])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "GQn0zGA-aBZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, network_input, network_output_pitch, network_output_duration, network_output_played, epochs):\n",
        "    # Create checkpoint to save the best model weights.\n",
        "    filepath = 'weights.hdf5'\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
        "    pitch_input=normalize_data(network_input[0])\n",
        "    duration_input=normalize_data(network_input[1])\n",
        "    played_input=normalize_data(network_input[2])\n",
        "    print(duration_input[0])\n",
        "    with tf.device(device_name):\n",
        "      history = model.fit(\n",
        "          [pitch_input, duration_input, played_input],  # Input data for each branch\n",
        "          [network_output_pitch, network_output_duration, network_output_played],  # Target data for each output\n",
        "          epochs=epochs, batch_size=50, callbacks=[checkpoint]\n",
        "    )\n",
        "    return history"
      ],
      "metadata": {
        "id": "FBDjbjv-aFLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    epochs = 200\n",
        "    notes = json.load(open('./Data/notes.json'))\n",
        "    print('Notes processed')\n",
        "    network_input, network_output_pitch, network_output_duration, network_output_played = prepare_sequences(notes)\n",
        "\n",
        "    num_of_sequences = len(network_input[0])\n",
        "    unique_pitch_num = len(set([item['pitch'] for item in notes]))\n",
        "    unique_duration_num = len(set([item['duration'] for item in notes]))\n",
        "\n",
        "    print('Input and Output processed')\n",
        "\n",
        "    with tf.device(device_name):\n",
        "      model = create_network(unique_pitch_num, unique_duration_num, num_of_sequences)\n",
        "        # Visualize the model architecture\n",
        "    plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "    # Display the image inline\n",
        "    Image('model.png')\n",
        "    print('Model created')\n",
        "\n",
        "    print('Training in progress')\n",
        "    print(model.summary())\n",
        "    history=train(model,network_input, network_output_pitch, network_output_duration, network_output_played, epochs)\n",
        "    print('Training completed')\n",
        "\n",
        "    # Visualize training loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "chN-7hoFaFz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from numpy.random import choice\n",
        "\n",
        "def generate_notes(model, network_input, pitch_dictionary, duration_dictionary, unique_pitch_num, unique_duration_num):\n",
        "\n",
        "    start = np.random.randint(0, len(network_input)-1)\n",
        "    int_to_pitch = dict((number, note) for number, note in enumerate(pitch_dictionary))\n",
        "    int_to_duration = dict((number, note) for number, note in enumerate(duration_dictionary))\n",
        "\n",
        "    pitch_input=network_input[0][start]\n",
        "    duration_input=network_input[1][start]\n",
        "    played_input=network_input[2][start]\n",
        "\n",
        "    pitch_input=np.squeeze(pitch_input)\n",
        "    duration_input=np.squeeze(duration_input)\n",
        "\n",
        "\n",
        "    pitch_prediction=[]\n",
        "    duration_prediction=[]\n",
        "    played_prediction=[]\n",
        "    prediction_output=[]\n",
        "\n",
        "\n",
        "    list_pitch=[]\n",
        "    list_duration=[]\n",
        "    for note_index in range(150):\n",
        "\n",
        "\n",
        "        batch_size = 1  # Assuming you are processing one batch at a time\n",
        "        time_steps = 50\n",
        "        input_features = 1  # Each input is a single value\n",
        "\n",
        "        #scaling data\n",
        "        pitch_input_normalized=normalize_data(np.reshape(pitch_input, (-1, 1)))\n",
        "        duration_input_normalized=normalize_data(np.reshape(duration_input, (-1, 1)))\n",
        "        played_input_normalized=played_input\n",
        "\n",
        "        pitch_input_reshaped = np.reshape(pitch_input_normalized, (batch_size, time_steps, input_features))\n",
        "        duration_input_reshaped = np.reshape(duration_input_normalized, (batch_size, time_steps, input_features))\n",
        "        played_input_reshaped = np.reshape(played_input_normalized, (batch_size, time_steps, input_features))\n",
        "\n",
        "        # Now you can create an input list for prediction\n",
        "\n",
        "        input_list = [pitch_input_reshaped, duration_input_reshaped, played_input_reshaped]\n",
        "\n",
        "        # Predict using the reshaped inputs\n",
        "        prediction = model.predict(input_list, verbose=0)\n",
        "\n",
        "        #random number\n",
        "        random_integer = random.randint(-3,-1)\n",
        "\n",
        "\n",
        "        pitch = prediction[0].ravel()\n",
        "        duration = prediction[1].ravel()\n",
        "\n",
        "        sorted_pitch = np.sort(pitch)\n",
        "        sorted_duration = np.sort(duration)\n",
        "\n",
        "        pitch_to_find = sorted_pitch[random_integer]\n",
        "        duration_to_find= sorted_duration[random_integer]\n",
        "\n",
        "        pitch_result = np.where(pitch == pitch_to_find)[0][0]\n",
        "        duration_result=np.where(duration == duration_to_find)[0][0]\n",
        "\n",
        "        list_pitch.append(pitch_result)\n",
        "        list_duration.append(duration_result)\n",
        "\n",
        "        if note_index==0:\n",
        "          played=1\n",
        "        else:\n",
        "          list_of_candidates=[1,0]\n",
        "          previous_pitch=list_pitch[note_index-1]\n",
        "          if previous_pitch == pitch_result:\n",
        "            probability_distribution=[0.15, 0.85]\n",
        "          else:\n",
        "            probability_distribution=[1.00, 0.00]\n",
        "\n",
        "\n",
        "          played=choice(list_of_candidates, 1,\n",
        "                p=probability_distribution)\n",
        "\n",
        "\n",
        "        print(played)\n",
        "\n",
        "        # Mapping the predicted interger back to the corresponding note\n",
        "        pitch = int_to_pitch[pitch_result]\n",
        "        duration = int_to_duration[duration_result]\n",
        "\n",
        "\n",
        "        pitch_prediction = np.append(pitch_prediction, pitch)\n",
        "        duration_prediction = np.append(duration_prediction, duration)\n",
        "        played_prediction = np.append(played_prediction, played)\n",
        "\n",
        "        #add predicted value\n",
        "        pitch_input=np.append(pitch_input,pitch_result)\n",
        "        duration_input=np.append(duration_input,duration_result)\n",
        "        played_input=np.append(played_input,played)\n",
        "\n",
        "        # Next input to the model\n",
        "        pitch_input = pitch_input[1:len(pitch_input)]\n",
        "        duration_input = duration_input[1:len(duration_input)]\n",
        "        played_input = played_input[1:len(played_input)]\n",
        "\n",
        "    prediction_output.append(pitch_prediction)\n",
        "    prediction_output.append(duration_prediction)\n",
        "    prediction_output.append(played_prediction)\n",
        "\n",
        "    print('Notes Generated...')\n",
        "\n",
        "    return prediction_output\n"
      ],
      "metadata": {
        "id": "5fUM2fo0aPSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate():\n",
        "    current_directory = os.getcwd()\n",
        "    print(\"Current Directory:\", current_directory)\n",
        "    notes = json.load(open('./Data/notes-bezRest.json'))\n",
        "    print('Notes processed')\n",
        "    network_input, network_output_pitch, network_output_duration, network_output_played = prepare_sequences(notes)\n",
        "    unique_pitch_num,pitch_dictionary=prepare_pitch_dictionary(notes)\n",
        "    unique_duration_num,duration_dictionary=prepare_duration_dictionary(notes)\n",
        "    network_input=np.array(network_input)\n",
        "    num_of_sequences = len(network_input[0])\n",
        "    print('Input and Output processed')\n",
        "\n",
        "    with tf.device(device_name):\n",
        "      model = create_network(unique_pitch_num, unique_duration_num, num_of_sequences)\n",
        "    print('Loading Model weights.....')\n",
        "    os.chdir('./Models')\n",
        "    current_directory = os.getcwd()\n",
        "    print(\"Current Directory:\", current_directory)\n",
        "\n",
        "    model.load_weights('model1_weights.hdf5')\n",
        "    print('Model Loaded')\n",
        "    os.chdir('..')\n",
        "    prediction_output = generate_notes(model, network_input, pitch_dictionary,duration_dictionary, unique_pitch_num, unique_duration_num)\n",
        "    durations = prediction_output[1]\n",
        "    # Count occurrences of 'r' in pitches\n",
        "    print(durations)\n",
        "\n",
        "    create_midi(prediction_output)"
      ],
      "metadata": {
        "id": "9ONUhAwfaIop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_midi(prediction_output):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    output_notes_index=-1\n",
        "    for index, pattern in enumerate(prediction_output[0]):\n",
        "       note_duration = prediction_output[1][index]\n",
        "       played=prediction_output[2][index]\n",
        "       print(played)\n",
        "       if(played==0):\n",
        "          print(output_notes_index)\n",
        "          print(\"--\")\n",
        "          print(len(output_notes))\n",
        "          offset += prediction_output[1][index]\n",
        "          old_duration= prediction_output[1][index-1]\n",
        "          new_duration= old_duration+note_duration\n",
        "          output_notes[output_notes_index].duration = duration.Duration(new_duration)\n",
        "          continue\n",
        "       else:\n",
        "          output_notes_index=output_notes_index+1\n",
        "          if pattern == 'r':\n",
        "            # Handle rests\n",
        "\n",
        "            new_rest = note.Rest()\n",
        "            new_rest.duration = duration.Duration(note_duration)\n",
        "            new_rest.offset = offset\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a chord\n",
        "          elif('.' in pattern) or pattern.isdigit():\n",
        "              notes_in_chord = pattern.split('.')\n",
        "              notes = []\n",
        "              for current_note in notes_in_chord:\n",
        "                  new_note = note.Note(int(current_note))\n",
        "                  new_note.storedInstrument = instrument.ElectricGuitar()\n",
        "                  notes.append(new_note)\n",
        "              new_chord = chord.Chord(notes)\n",
        "              new_chord.duration = duration.Duration(note_duration)\n",
        "              new_chord.offset = offset\n",
        "              output_notes.append(new_chord)\n",
        "          # pattern is a note\n",
        "          else:\n",
        "              new_note = note.Note(pattern)\n",
        "              new_note.offset = offset\n",
        "              new_note.duration = duration.Duration(note_duration)\n",
        "              new_note.storedInstrument = instrument.ElectricGuitar()\n",
        "              output_notes.append(new_note)\n",
        "\n",
        "          # increase offset each iteration so that notes do not stack\n",
        "          offset += prediction_output[1][index]\n",
        "\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    folder_path = '/content/ZavrsniRad/GeneratedSongs'\n",
        "    number = len(os.listdir(folder_path))+10\n",
        "    filename = f\"test{number}.mid\"\n",
        "    midi_stream.write('midi', fp=filename)"
      ],
      "metadata": {
        "id": "WrvQ9nTNFCIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(device_name):\n",
        "    model=train_model()\n",
        "generate()"
      ],
      "metadata": {
        "id": "BSxOkk9uulm2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}